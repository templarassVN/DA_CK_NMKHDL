{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STT: 34\n",
    "\n",
    "**Member**\n",
    "\n",
    "18120374 Nguyễn Minh Hiếu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thư viện cần dùng thêm:\n",
    "   * **ntlk**: để schemming (*ntlk.download()* chọn popular package)\n",
    "   * **re** để chuẩn hóa về a-z A-z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lợi ích:**\n",
    "* Nếu tìm được công thức thì công ty sản xuất có thể tự động hóa quá trình rút trích ý kiến thích / không thích từ các đoạn đánh giá của người dùng\n",
    "* Giúp công ty đánh giá được hiệu quả công việc. (Ở đây là AMAZON có thể kiểm tra sản phẩm được vận chuyển có đúng ý muốn khách hàng hay không)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cần làm :\n",
    "Tạo một list đọc từ file \"stop_word.txt\" gồm các từ vô ích (I'm, was, were, am, ...) để loại bỏ.\n",
    "\n",
    "Tạo một dict đọc từ file \"spell.txt\" để chuyển về đúng form VD: (dont, don't thành do not, doesnt, doen't thành does not, I'm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bước 1: Thu thập dữ liệu\n",
    "Đưa một link sản phẩm bất kì và kiểm tra phần đánh giá của khách hàng.\n",
    "* Đánh giá sẽ phân loại:*postive* và *critical*\n",
    "* Mỗi trang gồm 10 đánh giá, ta duyệt 250 trang cho mỗi loại đánh giá. Vậy tổng cộng 10x250x2 = 5000 đánh giá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây sẽ demo 3 trang cho mỗi loại đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.com/YI-Wireless-Security-Surveillance-Monitor/dp/B01CW4CEMS/ref=sr_1_47?dchild=1&qid=1610065358&s=electronics&sr=1-47'\n",
    "browser = webdriver.Chrome(executable_path='./chromedriver.exe') \n",
    "browser.maximize_window()\n",
    "browser.get(url)\n",
    "\n",
    "review_page = browser.find_element_by_link_text('See all reviews').click();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_types = browser.find_elements_by_css_selector('#reviewer-type-dropdown option')\n",
    "for reviewer_type in reviewer_types:\n",
    "    if \"Verified purchase only\" in reviewer_type.text:\n",
    "        reviewer_type.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_types = browser.find_elements_by_css_selector('#star-count-dropdown option')\n",
    "for comment_type in comment_types:\n",
    "    if \"All positive\" in comment_type.text:\n",
    "        comment_type.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = []\n",
    "status = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    time.sleep(3)\n",
    "    html_text = browser.page_source\n",
    "    tree = BeautifulSoup(html_text, 'html.parser')\n",
    "    reviews = tree.find_all('div',{'data-hook':'review'})\n",
    "    for review in reviews:\n",
    "        content = review.find('a', {'data-hook': 'review-title'})\n",
    "        phrases.append(content.text.strip())\n",
    "        status.append(1)\n",
    "    browser.find_element_by_class_name('a-last').click()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_types = browser.find_elements_by_css_selector('#star-count-dropdown option')\n",
    "for comment_type in comment_types:\n",
    "    if \"All critical\" in comment_type.text:\n",
    "        comment_type.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    time.sleep(3)\n",
    "    html_text = browser.page_source\n",
    "    tree = BeautifulSoup(html_text, 'html.parser')\n",
    "    reviews = tree.find_all('div',{'data-hook':'review'})\n",
    "    for review in reviews:\n",
    "        content = review.find('a', {'data-hook': 'review-title'})\n",
    "        phrases.append(content.text.strip())\n",
    "        status.append(0)\n",
    "    browser.find_element_by_class_name('a-last').click()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu dữ liệu thu thập được vào DataFrame và tạo file data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Data = pd.DataFrame(\n",
    "    {'Para': phrases,\n",
    "     'Stt': status\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kiểm tra data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data.to_csv('data.csv',index = False,encoding='utf-16',sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cột Para sẽ chứa các đánh giá\n",
    "* cột status gồm loại đánh giá tương ứng (1: positive - 0: critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Para</th>\n",
       "      <th>Stt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phenomenal for the price!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good home cameras for the price, but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent camera, couple of minor drawbacks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXCELLENT PICTURE (even at night) BUY THESE CA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great security cameras at a great price!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Para  Stt\n",
       "0                          Phenomenal for the price!    1\n",
       "1            Good home cameras for the price, but...    1\n",
       "2        Excellent camera, couple of minor drawbacks    1\n",
       "3  EXCELLENT PICTURE (even at night) BUY THESE CA...    1\n",
       "4           Great security cameras at a great price!    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv',encoding='utf-16',sep = '\\t')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dữ liệu trùng lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại bỏ trùng lặp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4379, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiểm tra thiếu dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Para    0\n",
       "Stt     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiểm tra độ cân bằng dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4845855218086321"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Stt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sr = data[\"Stt\"] # sr là viết tắt của series\n",
    "X_df = data.drop(\"Stt\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_df, val_X_df, train_y_sr, val_y_sr = train_test_split(X_df, y_sr, test_size=0.3, \n",
    "                                                              stratify=y_sr, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3065, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3065,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_sr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bước 2 tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta cần thực hiện các bước: loại phần thừa, áp dụng *stemming* \n",
    "* Stemming: đưa các từ có hình thức tương đồng nhau về từ gốc (Ở đây ta chưa bàn về ngữ cảnh).\n",
    "* Phần thừa như dấu câu, icon.\n",
    "\n",
    "Vì ta sử dụng tiếng Anh nên các từ có dấu (khác a-z A-Z) cũng sẽ bị loại bỏ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "#nltk.download() Chọn popular Package\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import  StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng **SnowballStemmer(\"english\")** để stemming các từ tiếng anh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishStemmer=SnowballStemmer(\"english\")\n",
    "#stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm **Recontruct_Sentence** để làm chuẩn và rút gọn các chữ trong đánh giá\n",
    "*  *re.sub('[^A-Za-z]',\"  \", sentence)* thay thế tất cả thành phần không thuộc bảng chữ cái thành dấu \" \"\n",
    "*  *append(englishStemmer.stem(word))* tạo một list gồm các từ sau khi đã stemming\n",
    "*  kết các từ lại thành câu và trả về câu đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recontruct_Sentence(sentence):\n",
    "    sentence = re.sub('[^A-Za-z]',' ', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(englishStemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class **trans_Sentence** dùng transform để biến *X_df* trở nên tối giản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test pipeline\n",
    "class trans_Sentence(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X_df, y=None):\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        # YOUR CODE HERE\n",
    "        optimize= []\n",
    "        self = X_df.copy()\n",
    "        sentence_s = self.Para\n",
    "        for sentence in sentence_s:\n",
    "            optimize.append(Recontruct_Sentence(sentence))\n",
    "        self.drop(['Para'],axis = 1)\n",
    "        self['Para'] = optimize\n",
    "        #print('trans', self.shape)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử nghiệm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Para</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>imag qualiti not improv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>good deal but could use some import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>camera are awesom custom support is none exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>alway offlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>was great but day later problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Para\n",
       "2939                         imag qualiti not improv \n",
       "2783             good deal but could use some import \n",
       "2541  camera are awesom custom support is none exist \n",
       "3584                                    alway offlin \n",
       "2917                 was great but day later problem "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_df = train_X_df\n",
    "test_trans_Sentence = trans_Sentence()\n",
    "test_X_df = test_trans_Sentence.fit_transform(test_X_df)\n",
    "test_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Về TfidfVectorizer có bài viết tham khảo ở [link](https://thorpham.github.io/blog/2018/04/14/setmentation/) và [document](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=fvector#sklearn.feature_extraction.text.TfidfVectorizer)\n",
    "\n",
    "Ở đây:\n",
    "* các tham số đầu vào là để cho việc tạo TfidfVectorizer() \n",
    "* **fit**       ta sẽ tạo một vector từ tập các từ ở trong trong *train_data*.\n",
    "* **transform** ta sẽ biến *val_data* thành một series gồm nhiều vector dựa trên vector đã fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toarray_Tidf(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,max_features = None, ngram_range = None, stop_words = None):\n",
    "        self.max_features = max_features\n",
    "        self.ngram_range = ngram_range\n",
    "        self.stop_words = stop_words \n",
    "        vect = TfidfVectorizer(max_features =  max_features, ngram_range =  ngram_range, stop_words =  self.stop_words)\n",
    "        self.vect = vect\n",
    "    def fit(self, X_df, y=None):\n",
    "        self.vect.fit(X_df.Para)\n",
    "        return self\n",
    "    def transform(self, X_df, y=None):\n",
    "        # YOUR CODE HERE\n",
    "        return self.vect.transform(X_df.Para).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1587"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = toarray_Tidf(max_features = None, ngram_range = (1,1), stop_words = None)\n",
    "series = vect.fit_transform(test_X_df)\n",
    "len(series[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vậy trong *train_X_df* có tổng cộng **1587 từ đơn** bao gồm các stop_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bước 3: Mô hình hóa dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo tạo mạng *Neural Network* và tạo **full_pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('trans_sentence', trans_Sentence()),\n",
       "                ('toarray_tidf',\n",
       "                 toarray_Tidf(ngram_range=(1, 1), stop_words={'english'})),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(activation='tanh', hidden_layer_sizes=10,\n",
       "                               max_iter=2750, random_state=0,\n",
       "                               solver='lbfgs'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural = MLPClassifier(hidden_layer_sizes = 10, activation='tanh', solver='lbfgs', random_state=0, max_iter = 2750)\n",
    "tidf = toarray_Tidf(stop_words = {'english'}, ngram_range = (1,1))\n",
    "full_pipeline = make_pipeline(trans_Sentence(), tidf, neural)\n",
    "\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành kiểm tra các tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max_features = [500,700,1100,None]\n",
    "num_alpha = [0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n",
      "trans (3065, 1)\n",
      "trans (3065, 1)\n",
      "trans (1314, 1)\n"
     ]
    }
   ],
   "source": [
    "train_errs = []\n",
    "val_errs = []\n",
    "best_val_err = float('inf')\n",
    "best_alpha = None\n",
    "best_best_feature = None\n",
    "for max_features in num_max_features:\n",
    "    for alpha in num_alpha:\n",
    "        pipe_prog.set_params(toarray_tidf__max_features= max_features, mlpclassifier__alpha=alpha)\n",
    "        let_fit = pipe_prog.fit(train_X_df,train_y_sr)\n",
    "        \n",
    "        error = (1- let_fit.score(train_X_df,train_y_sr))*100\n",
    "        train_errs.append(error)\n",
    "        \n",
    "        error = (1 - let_fit.score(val_X_df,val_y_sr))*100\n",
    "        val_errs.append(error)\n",
    "        \n",
    "        if (error < best_val_err):\n",
    "            best_val_err = error\n",
    "            best_alpha = alpha\n",
    "            best_feature = max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666664"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939    0\n",
       "2783    0\n",
       "2541    0\n",
       "3584    0\n",
       "2917    0\n",
       "       ..\n",
       "4233    0\n",
       "3638    0\n",
       "4270    0\n",
       "853     1\n",
       "2850    0\n",
       "Name: Stt, Length: 3065, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_sr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
